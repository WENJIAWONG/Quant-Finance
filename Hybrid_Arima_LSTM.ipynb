{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from pmdarima import auto_arima\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from talib import abstract\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(actual, prediction):\n",
    "    actual = pd.Series(actual)\n",
    "    prediction = pd.Series(prediction)\n",
    "    return 100 * np.mean(np.abs((actual - prediction))/actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arima(data, train_len, test_len):\n",
    "    # prepare train and test data\n",
    "    data = data.tail(test_len + train_len).reset_index(drop=True)\n",
    "    train = data.head(train_len).values.tolist()\n",
    "    test = data.tail(test_len).values.tolist()\n",
    "\n",
    "    # Initialize model\n",
    "    model = auto_arima(train, max_p=3, max_q=3, seasonal=False, trace=True,\n",
    "                       error_action='ignore', suppress_warnings=True)\n",
    "\n",
    "    # Determine model parameters\n",
    "    model.fit(train)\n",
    "    order = model.get_params()['order']\n",
    "    print('ARIMA order:', order, '\\n')\n",
    "\n",
    "    # Genereate predictions\n",
    "    prediction = []\n",
    "    for i in range(len(test)):\n",
    "        model = pm.ARIMA(order=order)\n",
    "        model.fit(train)\n",
    "        print('working on', i+1, 'of', test_len, '-- ' + str(int(100 * (i + 1) / test_len)) + '% complete')\n",
    "        prediction.append(model.predict()[0])\n",
    "        train.append(test[i])\n",
    "\n",
    "    # Generate error data\n",
    "    mse = mean_squared_error(test, prediction)\n",
    "    rmse = mse ** 0.5\n",
    "    mape = mean_absolute_percentage_error(pd.Series(test), pd.Series(prediction))\n",
    "    return prediction, mse, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm(data, train_len, test_len, lstm_len=4):\n",
    "    # prepare train and test data\n",
    "    data = data.tail(test_len + train_len).reset_index(drop=True)\n",
    "    dataset = np.reshape(data.values, (len(data), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset_scaled = scaler.fit_transform(dataset)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "\n",
    "    for i in range(lstm_len, train_len):\n",
    "        x_train.append(dataset_scaled[i - lstm_len:i, 0])\n",
    "        y_train.append(dataset_scaled[i, 0])\n",
    "    for i in range(train_len, len(dataset_scaled)):\n",
    "        x_test.append(dataset_scaled[i - lstm_len:i, 0])\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    \n",
    "      # Set up & fit LSTM RNN\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_len, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(LSTM(units=int(lstm_len/2)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    early_stopping = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "    model.fit(x_train, y_train, epochs=500, batch_size=1, verbose=2, callbacks=[early_stopping])\n",
    "     # Generate predictions\n",
    "    prediction = model.predict(x_test)\n",
    "    prediction = scaler.inverse_transform(prediction).tolist()\n",
    "\n",
    "    output = []\n",
    "    for i in range(len(prediction)):\n",
    "        output.extend(prediction[i])\n",
    "    prediction = output\n",
    "\n",
    "    # Generate error data\n",
    "    mse = mean_squared_error(data.tail(len(prediction)).values, prediction)\n",
    "    rmse = mse ** 0.5\n",
    "    mape = mean_absolute_percentage_error(data.tail(len(prediction)).reset_index(drop=True), pd.Series(prediction))\n",
    "    return prediction, mse, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load historical data\n",
    "    # CSV should have columns: ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    data = pd.read_csv('TSLA_test.csv', index_col=0, header=0).tail(1500).reset_index(drop=True)\n",
    "    # Initialize moving averages from Ta-Lib, store functions in dictionary\n",
    "    talib_moving_averages = ['SMA', 'EMA', 'WMA', 'DEMA', 'KAMA', 'MIDPOINT', 'MIDPRICE', 'T3', 'TEMA', 'TRIMA']\n",
    "    functions = {}\n",
    "    for ma in talib_moving_averages:\n",
    "        functions[ma] = abstract.Function(ma)\n",
    "    # Determine kurtosis \"K\" values for MA period 4-99\n",
    "    kurtosis_results = {'period': []}\n",
    "    for i in range(4, 100):\n",
    "        kurtosis_results['period'].append(i)\n",
    "        for ma in talib_moving_averages:\n",
    "            # Run moving average, remove last 252 days (used later for test data set), trim MA result to last 60 days\n",
    "            ma_output = functions[ma](data[:-252], i).tail(60)\n",
    "\n",
    "            # Determine kurtosis \"K\" value\n",
    "            k = kurtosis(ma_output, fisher=False)\n",
    "\n",
    "            # add to dictionary\n",
    "            if ma not in kurtosis_results.keys():\n",
    "                kurtosis_results[ma] = []\n",
    "            kurtosis_results[ma].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    kurtosis_results = pd.DataFrame(kurtosis_results)\n",
    "    kurtosis_results.to_csv('kurtosis_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMA is not viable, best K greater or less than 3 +/-5%\n",
      "\n",
      "Optimized periods: {'SMA': 20, 'EMA': 45, 'DEMA': 68, 'KAMA': 10, 'MIDPOINT': 63, 'MIDPRICE': 83, 'T3': 23, 'TEMA': 93, 'TRIMA': 34}\n"
     ]
    }
   ],
   "source": [
    "    # Determine period with K closest to 3 +/-5%\n",
    "    optimized_period = {}\n",
    "    for ma in talib_moving_averages:\n",
    "        difference = np.abs(kurtosis_results[ma] - 3)\n",
    "        df = pd.DataFrame({'difference': difference, 'period': kurtosis_results['period']})\n",
    "        df = df.sort_values(by=['difference'], ascending=True).reset_index(drop=True)\n",
    "        if df.at[0, 'difference'] < 3 * 0.05:\n",
    "            optimized_period[ma] = df.at[0, 'period']\n",
    "        else:\n",
    "            print(ma + ' is not viable, best K greater or less than 3 +/-5%')\n",
    "\n",
    "    print('\\nOptimized periods:', optimized_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid parameter value for timeperiod (expected int, got int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b7477d3ee864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimized_period\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Split data into low volatility and high volatility time series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mlow_vol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimized_period\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mhigh_vol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'close'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlow_vol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_abstract.pxi\u001b[0m in \u001b[0;36mtalib._ta_lib.Function.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_abstract.pxi\u001b[0m in \u001b[0;36mtalib._ta_lib.Function.set_function_args\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_abstract.pxi\u001b[0m in \u001b[0;36mtalib._ta_lib.Function.__check_opt_input_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid parameter value for timeperiod (expected int, got int64)"
     ]
    }
   ],
   "source": [
    "    simulation = {}\n",
    "    for ma in optimized_period:\n",
    "        # Split data into low volatility and high volatility time series\n",
    "        low_vol = functions[ma](data, optimized_period[ma])\n",
    "        high_vol = data['close'] - low_vol\n",
    "\n",
    "        # Generate ARIMA and LSTM predictions\n",
    "        print('\\nWorking on ' + ma + ' predictions')\n",
    "        try:\n",
    "            low_vol_prediction, low_vol_mse, low_vol_rmse, low_vol_mape = get_arima(low_vol, 1000, 252)\n",
    "        except:\n",
    "            print('ARIMA error, skipping to next MA type')\n",
    "            continue\n",
    "\n",
    "        high_vol_prediction, high_vol_mse, high_vol_rmse, high_vol_mape = get_lstm(high_vol, 1000, 252)\n",
    "\n",
    "        final_prediction = pd.Series(low_vol_prediction) + pd.Series(high_vol_prediction)\n",
    "        mse = mean_squared_error(final_prediction.values, data['close'].tail(252).values)\n",
    "        rmse = mse ** 0.5\n",
    "        mape = mean_absolute_percentage_error(data['close'].tail(252).reset_index(drop=True), final_prediction)\n",
    "        # Generate prediction accuracy\n",
    "        actual = data['close'].tail(252).values\n",
    "        result_1 = []\n",
    "        result_2 = []\n",
    "        for i in range(1, len(final_prediction)):\n",
    "            # Compare prediction to previous close price\n",
    "            if final_prediction[i] > actual[i-1] and actual[i] > actual[i-1]:\n",
    "                result_1.append(1)\n",
    "            elif final_prediction[i] < actual[i-1] and actual[i] < actual[i-1]:\n",
    "                result_1.append(1)\n",
    "            else:\n",
    "                result_1.append(0)\n",
    "\n",
    "            # Compare prediction to previous prediction\n",
    "            if final_prediction[i] > final_prediction[i-1] and actual[i] > actual[i-1]:\n",
    "                result_2.append(1)\n",
    "            elif final_prediction[i] < final_prediction[i-1] and actual[i] < actual[i-1]:\n",
    "                result_2.append(1)\n",
    "            else:\n",
    "                result_2.append(0)\n",
    "                \n",
    "            accuracy_1 = np.mean(result_1)\n",
    "            accuracy_2 = np.mean(result_2)\n",
    "            simulation[ma] = {'low_vol': {'prediction': low_vol_prediction, 'mse': low_vol_mse,\n",
    "                                      'rmse': low_vol_rmse, 'mape': low_vol_mape},\n",
    "                              'high_vol': {'prediction': high_vol_prediction, 'mse': high_vol_mse,\n",
    "                                       'rmse': high_vol_rmse},\n",
    "                              'final': {'prediction': final_prediction.values.tolist(), 'mse': mse,\n",
    "                                    'rmse': rmse, 'mape': mape},\n",
    "                              'accuracy': {'prediction vs close': accuracy_1, 'prediction vs prediction': accuracy_2}}\n",
    "            # save simulation data here as checkpoint\n",
    "            with open('simulation_data.json', 'w') as fp:\n",
    "                json.dump(simulation, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for ma in simulation.keys():\n",
    "        print('\\n' + ma)\n",
    "        print('Prediction vs Close:\\t\\t' + str(round(100*simulation[ma]['accuracy']['prediction vs close'], 2))\n",
    "              + '% Accuracy')\n",
    "        print('Prediction vs Prediction:\\t' + str(round(100*simulation[ma]['accuracy']['prediction vs prediction'], 2))\n",
    "              + '% Accuracy')\n",
    "        print('MSE:\\t', simulation[ma]['final']['mse'],\n",
    "              '\\nRMSE:\\t', simulation[ma]['final']['rmse'],\n",
    "              '\\nMAPE:\\t', simulation[ma]['final']['mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
